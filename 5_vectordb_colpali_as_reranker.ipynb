{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "V1FIvS0SV5_F",
        "ZyvXUxuCajk2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rachnas/vision-RAG/blob/main/5_vectordb_colpali_as_reranker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "V1FIvS0SV5_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colpali-engine==0.3.2\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "2wWrFkngseSe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install poppler-utils"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xizOl0nky46U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Visual Language Model (ColPali)"
      ],
      "metadata": {
        "id": "ZyvXUxuCajk2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RgSMeBUrJD2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from colpali_engine.models import ColPali, ColPaliProcessor\n",
        "\n",
        "model_name = \"vidore/colpali-v1.3\"\n",
        "\n",
        "model = ColPali.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"cuda:0\",  # or \"mps\" if on Apple Silicon\n",
        ").eval()\n",
        "\n",
        "processor = ColPaliProcessor.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process PDF\n",
        "*   Define Colpali class\n",
        "*   Create image and query embeddings\n",
        "*   Late interaction\n",
        "*   Display output\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nvk-SCT2awHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9cC2Ro09AsNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class colpali_class():\n",
        "  def __init__(self,processor,model):\n",
        "    self.processor = processor\n",
        "    self.model = model\n",
        "\n",
        "  def embed_image(self, list_of_images):\n",
        "    dataset = []\n",
        "    for img in list_of_images:\n",
        "      images = convert_from_path(img)\n",
        "      dataloader = DataLoader(images, batch_size=1, shuffle=False, collate_fn=lambda x:self.processor.process_images(x).to(self.model.device))\n",
        "      for batch in tqdm(dataloader):\n",
        "        with torch.no_grad():\n",
        "          batch = {k: v.to(self.model.device) for k,v in batch.items()}\n",
        "          embeddings = self.model(**batch)\n",
        "        dataset.extend(list(torch.unbind(embeddings.to(\"cpu\").to(torch.float32))))\n",
        "    return dataset\n",
        "\n",
        "  def embed_query(self, query):\n",
        "    batch_queries = processor.process_queries(query).to(model.device)\n",
        "    with torch.no_grad():\n",
        "      query_embeddings = model(**batch_queries)\n",
        "      query_embeddings = list(torch.unbind(query_embeddings.to(\"cpu\").to(torch.float32)))\n",
        "    return query_embeddings\n",
        "\n",
        "  def score(self, query_embedding, dataset):\n",
        "    scores = processor.score_multi_vector(query_embedding, dataset)\n",
        "    scores = np.array(scores)\n",
        "    matched_pages = scores.flatten().argsort()[::-1]\n",
        "    return scores, matched_pages"
      ],
      "metadata": {
        "id": "uqN1bt-Em0rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colpali_obj = colpali_class(processor, model)"
      ],
      "metadata": {
        "id": "HLl75P44pJWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"sample_data/AT&T_esg_doc.pdf\""
      ],
      "metadata": {
        "id": "T6VEICThLkhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = colpali_obj.embed_image([file_name])"
      ],
      "metadata": {
        "id": "vUS2FdMrpbbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset), dataset[0].shape"
      ],
      "metadata": {
        "id": "XZ3X_A3tqLLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = ['how much carbon reduction is expected in transportation?']\n",
        "query_embeddings = colpali_obj.embed_query(query)"
      ],
      "metadata": {
        "id": "GXiLsTTfqVbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(query_embeddings), query_embeddings[0].shape"
      ],
      "metadata": {
        "id": "u_ZVZ9BoqVef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores, matched_pages = colpali_obj.score(query_embeddings, dataset)"
      ],
      "metadata": {
        "id": "3mJuXQkEQf4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores, matched_pages"
      ],
      "metadata": {
        "id": "C_kd59LdQ5o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = convert_from_path(file_name)"
      ],
      "metadata": {
        "id": "Er4citlzrSfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "id": "Sr-tJ_gARcXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 12))\n",
        "ax.imshow(images[matched_pages[0]])\n",
        "ax.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vyn868PHRJTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector DB\n",
        "- Initialize faiss vector DB\n"
      ],
      "metadata": {
        "id": "nFl9F2KErcc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install langchain_community\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "yj857sS-rrz5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "j7PxY4RArYrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.IndexFlatL2(128)\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=colpali_obj.embed_query,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")"
      ],
      "metadata": {
        "id": "wsPjtXUur69x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add embeddings to FAISS Vector DB\n",
        "*   Create metadata\n",
        "*   Add document to DB with metadata"
      ],
      "metadata": {
        "id": "HkUXf9i704gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir sample_data/data"
      ],
      "metadata": {
        "id": "QwEh5iEL9R3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "from PIL import Image\n",
        "file_name = file_name\n",
        "all_images = []\n",
        "for i, img in enumerate(images):\n",
        "  page_name = \"sample_data/data/\"+str(i)+\".pdf\"\n",
        "  img = img.resize((800,800),Image.LANCZOS)\n",
        "  img.save(page_name)\n",
        "  all_images.append(page_name)\n",
        "\n",
        "all_embeddings = [l for l in dataset]\n",
        "list_of_tuple = []\n",
        "for img, embd in zip(all_images, all_embeddings):\n",
        "  for i in range(0,1030):\n",
        "    list_of_tuple.append((img, embd[i]))\n",
        "\n",
        "metadata = []\n",
        "uids = []\n",
        "count=0\n",
        "pdfReader = PyPDF2.PdfReader(file_name)\n",
        "total_pages = len(pdfReader.pages)\n",
        "for i in range(0,total_pages):\n",
        "  for j in range(0,1030):\n",
        "    file_name = file_name\n",
        "    page_name = file_name.split(\"/\")[-1].split(\".\")[0]+\"_\"+str(i)+\".pdf\"\n",
        "    patch_num = j\n",
        "    uid = count\n",
        "    metadata.append({\"file_name\":file_name, \"page_name\": page_name, \"patch_num\":patch_num,\"uid\":uid})\n",
        "    uids.append(uid)\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "DpVa4m2hsgRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = vector_store.add_embeddings(text_embeddings= list_of_tuple, metadatas=metadata, ids = uids)"
      ],
      "metadata": {
        "id": "dqGkUjMsr7Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#index_to_docstore_id = vector_store.index_to_docstore_id\n",
        "#uid_to_del = []\n",
        "#for i in range(0,len(index_to_docstore_id)):\n",
        "#  uid_to_del.append(vector_store.docstore._dict[index_to_docstore_id[i]].metadata['uid'])\n",
        "#vector_store.delete(ids=uid_to_del)"
      ],
      "metadata": {
        "id": "3E1dEHNlGWgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do similarity search\n",
        "\n",
        "\n",
        "*   Match each word of query with patch in DB\n",
        "*   Get all the page names and sort based on frequency of occurance\n",
        "\n"
      ],
      "metadata": {
        "id": "HC8zuh-8Qc-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page_name_list = []\n",
        "for i in range(0,query_embeddings[0].shape[0]):\n",
        "    vec = query_embeddings[0][i].tolist()\n",
        "    results = vector_store.similarity_search_by_vector(vec, k=3)\n",
        "    for doc in results:\n",
        "       page_name_list.append(doc.metadata['page_name'])"
      ],
      "metadata": {
        "id": "MA3kR6M8DIJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hLcrR0ruO675"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_list_items = set(page_name_list)\n",
        "page_dict={}\n",
        "\n",
        "for list_item in unique_list_items:\n",
        "    page_dict[list_item]=page_name_list.count(list_item)\n",
        "sorted_page_dict = dict(sorted(page_dict.items(),key=lambda item: item[1], reverse=True))\n",
        "top_pages = list(sorted_page_dict.keys())\n",
        "top_pages"
      ],
      "metadata": {
        "id": "VVGOpoLH3jwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rerank vector DB output using colpali late interaction\n",
        "*  Get page embeddings from DB\n",
        "*  Call score function of colpali\n",
        "\n"
      ],
      "metadata": {
        "id": "q6QBazSCPjsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_doc_embeddings(page_names_list):\n",
        "  doc_vectors = []\n",
        "  for page_name in page_names_list:\n",
        "\n",
        "      page_num = page_name.split(\"_\")[-1].split(\".\")[0]\n",
        "      page_num = int(page_num)\n",
        "      doc_vectors.append(vector_store.index.reconstruct_n(page_num*1030,1030))\n",
        "\n",
        "  doc_embd = torch.from_numpy(np.stack(doc_vectors))\n",
        "  return doc_embd"
      ],
      "metadata": {
        "id": "xsS-G6AJBp5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embd = get_doc_embeddings(top_pages)\n",
        "print(doc_embd.shape)"
      ],
      "metadata": {
        "id": "MPSJL6VJ13tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores, matched_pages = colpali_obj.score(query_embeddings, doc_embd)"
      ],
      "metadata": {
        "id": "xGMEChCOO0IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores, matched_pages"
      ],
      "metadata": {
        "id": "zmwCbJe2O0MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_page_name = top_pages[matched_pages[0]]\n",
        "final_page_name"
      ],
      "metadata": {
        "id": "70yVWPc0NWOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 12))\n",
        "ax.imshow(images[2])\n",
        "ax.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SgUgB0oDPHJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation model\n",
        "*   Model setup\n",
        "*   Call model with reranker output\n",
        "\n"
      ],
      "metadata": {
        "id": "oy76WC-KRC5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qwen-vl-utils==0.0.08"
      ],
      "metadata": {
        "id": "S0EzlZtq9ftr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "# default: Load the model on the available device(s)\n",
        "gen_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "    \"Qwen/Qwen2.5-VL-3B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
        ")\n",
        "# default processer\n",
        "gen_processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")"
      ],
      "metadata": {
        "id": "XbEErsrg9f1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images, final_page_name"
      ],
      "metadata": {
        "id": "VjfnqwbXRrJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page_numbers(all_images, page_name):\n",
        " page_num = page_name.split(\"_\")[-1].split(\".\")[0]\n",
        " local_page_name = \"sample_data/data/\"+str(page_num)+\".pdf\"\n",
        " return int(page_num), local_page_name"
      ],
      "metadata": {
        "id": "BDfy6Gdk-Ehp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_num,local_page_name = get_page_numbers(all_images, final_page_name)\n",
        "print(page_num)"
      ],
      "metadata": {
        "id": "SZ75otqw-aBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": [\n",
        "         {\"type\": \"image\",\n",
        "          \"image\": images[page_num],\n",
        "          \"resized_height\": 800,\n",
        "          \"resized_width\": 800,\n",
        "         },\n",
        "        {\"type\": \"text\", \"text\": query}]},\n",
        "]"
      ],
      "metadata": {
        "id": "Tf2dCeVW9q4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation for inference\n",
        "text = gen_processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "image_inputs, video_inputs = process_vision_info(messages)\n",
        "inputs = gen_processor(\n",
        "    text=[text],\n",
        "    images=image_inputs,\n",
        "    videos=video_inputs,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "inputs = inputs.to(\"cuda\")"
      ],
      "metadata": {
        "id": "UQ55qNL29q6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inference: Generation of the output\n",
        "import torch\n",
        "with torch.no_grad():\n",
        "  generated_ids = gen_model.generate(**inputs, max_new_tokens=64)\n",
        "\n",
        "generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "]\n",
        "output_text = gen_processor.batch_decode(\n",
        "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        ")\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "dvvfMCj59yE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}